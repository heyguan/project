{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ex1.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1UA-0Y2sXUmk9gJl7tbRZIlml6cWS11JC","authorship_tag":"ABX9TyOAsz8AOOdAMd9++2tHxsMO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"KKpyGrRABVpW"},"source":["1. upload png_data.zip to google drive\n","2. unzip png_data.zip to /content\n","3. install monai, torchio, pydicom packages"]},{"cell_type":"code","metadata":{"id":"Bke8jQPNM0kZ"},"source":["!7z x -aos /content/drive/MyDrive/png_data.zip -o/content\n","!pip install pydicom\n","!pip install torchio\n","!pip install monai"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y00-ZGpENQor","executionInfo":{"status":"ok","timestamp":1635598601091,"user_tz":-60,"elapsed":2329,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["import glob\n","import os\n","import cv2\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset,DataLoader\n","import pydicom\n","import numpy as np\n","from pydicom.pixel_data_handlers.util import apply_voi_lut\n","from torchvision import transforms, utils\n","import pandas as pd\n","from PIL import Image\n","from sklearn.metrics import roc_auc_score\n","import torchio as tio\n","from sklearn.model_selection import train_test_split\n","import re\n","import matplotlib.pyplot as plt\n","import monai\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm.notebook import tqdm"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"89M6S9eiG8u0"},"source":["In experiment A-1, I only using one type of MRI to train densenet-121 or shallow CNN model. \n","\n","So here available mri_selected=['FLAIR', 'T1w', 'T1wCE', 'T2w'], available model_selected = ['densenet', 'shallow']\n","\n","change the mritype_selected and model_selected to do experiment A-1"]},{"cell_type":"code","metadata":{"id":"PdU9L7a4Pv4g","executionInfo":{"status":"ok","timestamp":1635598601092,"user_tz":-60,"elapsed":5,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["data_directory='/content/png_voxel_converted_ds'\n","NUM_IMAGES=36\n","IMAGE_SIZE=224\n","\n","mri_selected = 'FLAIR' # or 'T1w', 'T1wCE', 'T2w'\n","model_selected = 'shallow' # or 'shallow'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"1NPSMrQaNSmd","executionInfo":{"status":"ok","timestamp":1635598601092,"user_tz":-60,"elapsed":5,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["# load png files, rotate and resize images\n","def load_2dimage(file,rotate= 0):\n","  img = Image.open(file)\n","  img = np.array(img)\n","  height, width = img.shape[:2]\n","  center = (width // 2, height // 2)\n","      \n","  if rotate != 0:\n","    M = cv2.getRotationMatrix2D(center, rotate, 1)\n","    img = cv2.warpAffine(img, M, (width, height))\n","    \n","  img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n","\n","  return img\n","\n","# stack all 2d png to be a single 3D images\n","def load_3dimage(ids, num_imgs=NUM_IMAGES, split='train', img_size=IMAGE_SIZE, mri_type='FLAIR',rotate = 0):\n","  files = sorted(glob.glob(f\"{data_directory}/{split}/{ids}/{mri_type}/*.png\"), \n","               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n","  middle = len(files)//2\n","  num_imgs2 = num_imgs//2\n","  p1 = max(0, middle - num_imgs2)\n","  p2 = min(len(files), middle + num_imgs2)\n","  img3d = np.stack([load_2dimage(f,rotate = rotate) for f in files[p1:p2]]).T #不知道要不要.T\n","\n","  if img3d.shape[-1] < num_imgs:\n","    n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n","    img3d = np.concatenate((img3d,  n_zero), axis = -1)\n","        \n","  if np.min(img3d) < np.max(img3d):\n","    img3d = img3d - np.min(img3d)\n","    img3d = img3d / np.max(img3d)\n","  return img3d\n","\n","\n","class PNG_dataset(Dataset):\n","  def __init__(self, df, is_train=True,test = False, split='train', mritype='FLAIR',label_smoothing = 0.01):\n","    self.ids = df[\"BraTS21ID\"].values\n","    self.y =  df[\"MGMT_value\"].values\n","    self.is_train = is_train\n","    self.mritype = mritype\n","    self.label_smoothing = label_smoothing\n","    self.test = test\n","    self.split = split\n","\n","  def __len__(self):\n","    return len(self.ids)\n","\n","  def __getitem__(self, idx):\n","    id1 = str(self.ids[idx]).zfill(5)\n","    label = self.y[idx]\n","    rotate_prob = np.random.randint(0,10) # set rotate probability\n","    if self.is_train and rotate_prob>8:\n","      ro = np.random.randint(-15, 15)\n","    else:\n","      ro = 0  \n","    list_x =  load_3dimage(id1, split = self.split, mri_type = self.mritype, rotate = ro) # load 3d image\n","\n","    opti_trans_1 = {\n","      tio.RandomMotion():0.3,\n","      tio.RandomBiasField():0.3,\n","      }\n","    opti_trans_2 = {\n","      tio.RandomFlip():0.5,\n","      tio.RandomAnisotropy():0.5,\n","      }\n","    transforms_io = tio.Compose([\n","      tio.OneOf(opti_trans_1, p=0.4),\n","      tio.OneOf(opti_trans_2, p=0.4),\n","      tio.RandomNoise(p=0.15),\n","      tio.RescaleIntensity(out_min_max=(-1, 1))\n","      ])\n","    \n","    transforms_io_test = tio.Compose([\n","      tio.RescaleIntensity(out_min_max=(-1, 1))\n","      ])\n","\n","    transform = transforms.Compose([\n","      transforms.ToTensor()\n","    ])\n","    list_x = transform(list_x) \n","    list_x = list_x.unsqueeze(0)\n","\n","    if self.is_train == True:\n","      list_x = transforms_io(list_x)\n","    else:\n","      list_x = transforms_io_test(list_x)\n","\n","    \n","    if self.test == True:\n","      return torch.as_tensor(list_x, dtype=torch.float), id1\n","    else:\n","      return torch.as_tensor(list_x, dtype=torch.float), torch.tensor(label, dtype=torch.long)\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"DiNxA9RiVL70","executionInfo":{"status":"ok","timestamp":1635598601093,"user_tz":-60,"elapsed":5,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["origin_df = pd.read_csv('/content/train_labels.csv')\n","df_train, df_valid1 = train_test_split(origin_df, test_size=0.2, random_state=42,stratify=origin_df[\"MGMT_value\"]) # split dataset and we get training set, validation set, test_set\n","df_valid, df_test = train_test_split(df_valid1, test_size=0.5, random_state=42)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"LopIRsppVm2U"},"source":["train_dataset = PNG_dataset(df_train, is_train=True, mritype = mri_selected)\n","val_dataset = PNG_dataset(df_valid,is_train=False,mritype = mri_selected)\n","test_dataset = PNG_dataset(df_test,is_train=False,mritype = mri_selected)\n","\n","train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=4, pin_memory=torch.cuda.is_available())\n","val_loader = DataLoader(val_dataset, batch_size=12, shuffle=True, num_workers=4, pin_memory=torch.cuda.is_available())\n","test_loader = DataLoader(test_dataset, batch_size=12, shuffle=True, num_workers=4, pin_memory=torch.cuda.is_available())\n","\n","print(\"len of train data\", len(train_dataset))\n","print(\"len of valid data\", len(val_dataset))\n","print(\"len of train batch\", len(train_loader))\n","print(\"len of valid batch\", len(val_loader))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"52jL1kZ1HWe2","executionInfo":{"status":"ok","timestamp":1635598601656,"user_tz":-60,"elapsed":5,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["class Block(nn.Module):\n","  def __init__(self, in_c, out_c, drop_rate=0.0):\n","    super(Block, self).__init__()\n","\n","    layers = [nn.Conv3d(in_c, out_c, 3, 1, 1),\n","          nn.ReLU(),\n","          nn.MaxPool3d(2,stride=2),\n","          nn.BatchNorm3d(out_c)]\n","\n","    if drop_rate > 0:\n","      layers += [nn.Dropout(drop_rate)]\n","\n","    self.features = nn.Sequential(*layers)\n","\n","  def forward(self, x):\n","    return self.features(x)\n","\n","class shallow_model(nn.Module):\n","  def __init__(self, num_classes=2, n_init_features=1):\n","    super(shallow_model, self).__init__()\n","    self.conv1 = Block(n_init_features, 32)\n","    self.conv2 = Block(32, 64,drop_rate=0.02)\n","    self.conv3 = Block(64, 128,drop_rate=0.04)\n","    self.conv4 = Block(128, 256,drop_rate=0.08)\n","    # self.conv_fea = nn.Conv3d(993, 512, 3, 1, 1)\n","    self.avg = nn.AdaptiveAvgPool3d(1)\n","    self.fc1 = nn.Linear(256, 1024)\n","    self.drop = nn.Dropout(0.08)\n","    self.relu1 = nn.ReLU()\n","    self.fc2 = nn.Linear(1024, num_classes)\n","    self.fla = nn.Flatten()\n","\n","\n","  def forward(self,x):\n","    x1 = self.conv1(x)\n","    x2 = self.conv2(x1)\n","    x3 = self.conv3(x2)\n","    x4 = self.conv4(x3)\n","\n","    x6 = self.avg(x4)\n","    x7 = self.fla(x6)\n","    x8 = self.fc1(x7)\n","    x10 = self.relu1(x8)\n","    x11 = self.fc2(x10)\n","    return x11"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"DGWqGV9YZuCS"},"source":["%load_ext tensorboard\n","%tensorboard --logdir runs\n","%reload_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"igXQJmN1ZUa9","executionInfo":{"status":"ok","timestamp":1635598604573,"user_tz":-60,"elapsed":2920,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if model_selected == 'densenet':\n","  model = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=2).to(device)\n","if model_selected == 'shallow':\n","  model = shallow_model().to(device)\n","\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n","# scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: 0.9**epoch)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"GrZHWz_FL9OI"},"source":["val_interval = 1 \n","best_metric = -1\n","best_auc = -1\n","best_metric_epoch = -1\n","best_auc_epoch = -1\n","epoch_loss_values = list()\n","metric_values = list()\n","writer = SummaryWriter()\n","\n","train_loss = []\n","valid_loss = []\n","test_loss = []\n","valid_acc = []\n","valid_auc= []\n","test_acc = []\n","test_auc = []\n","for epoch in range(200):\n","  print(\"-\" * 10)\n","  print(f\"epoch {epoch + 1}/{200}\")\n","  model.train()\n","  epoch_loss = 0\n","  step = 0\n","  val_step = 0\n","  for batch_data in train_loader:\n","    step += 1\n","    inputs, labels = batch_data\n","    inputs = inputs.to(device)\n","    labels = labels.to(device)\n","    optimizer.zero_grad()\n","    outputs = model(inputs)\n","    loss = loss_function(outputs, labels)\n","    loss.backward()\n","    optimizer.step()\n","    epoch_loss += loss.item()\n","\n","  current_lr = optimizer.state_dict()['param_groups'][0]['lr']\n","  writer.add_scalar(\"learning rate\", current_lr, epoch+1)\n","  # scheduler.step()\n","  epoch_loss /= step\n","  epoch_loss_values.append(epoch_loss) # avg train loss\n","  train_loss.append(epoch_loss)\n","  writer.add_scalar(\"train_loss\", epoch_loss, epoch+1)\n","\n","  print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n","\n","  if (epoch + 1) % val_interval == 0:\n","    model.eval()\n","    with torch.no_grad():\n","      num_correct = 0.0\n","      metric_count = 0\n","      all_labels = []\n","      prob = []\n","      val_step=0\n","      val_loss_epoch=0\n","      for val_data in val_loader:\n","        val_step += 1\n","        val_images, val_labels = val_data\n","        val_images = val_images.to(device)\n","        val_labels = val_labels.to(device)\n","        val_outputs = model(val_images)\n","        val_loss = loss_function(val_outputs, val_labels)\n","        value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n","        val_loss_epoch += val_loss.item()\n","        metric_count += len(value)\n","        num_correct += value.sum().item()\n","        prob_positive = torch.softmax(val_outputs, dim=1)[:, 1]\n","        prob_positive111 = prob_positive.cpu().numpy()\n","        for a in prob_positive111:\n","          prob.append(a)\n","        x_labels = val_labels.cpu().numpy()\n","        for a in x_labels:\n","          all_labels.append(a)\n","\n","      val_auc = roc_auc_score(all_labels,prob)\n","      avg_val_loss = val_loss_epoch / val_step\n","      valid_loss.append(avg_val_loss) # avg valid loss\n","      valid_auc.append(val_auc) #avg valid auc\n","      \n","      metric = num_correct / metric_count\n","      valid_acc.append(metric)\n","      writer.add_scalar(\"valid_loss\", avg_val_loss, epoch+1)\n","      writer.add_scalar(\"val_accuracy\", metric, epoch + 1)\n","      writer.add_scalar(\"val_AUC\", val_auc, epoch + 1)\n","\n","  # below is test part\n","  if (epoch + 1) % val_interval == 0:\n","    model.eval()\n","    with torch.no_grad():\n","      num_correct = 0.0\n","      metric_count = 0\n","      all_labels = []\n","      prob = []\n","      val_step=0\n","      val_loss_epoch=0\n","      for val_data in test_loader:\n","        val_step += 1\n","        val_images, val_labels = val_data\n","        val_images = val_images.to(device)\n","        val_labels = val_labels.to(device)\n","        val_outputs = model(val_images)\n","        val_loss = loss_function(val_outputs, val_labels)\n","        value = torch.eq(val_outputs.argmax(dim=1), val_labels)\n","        val_loss_epoch += val_loss.item()\n","        metric_count += len(value)\n","        num_correct += value.sum().item()\n","\n","        prob_positive = torch.softmax(val_outputs, dim=1)[:, 1]\n","        prob_positive111 = prob_positive.cpu().numpy()\n","        for a in prob_positive111:\n","          prob.append(a)\n","        x_labels = val_labels.cpu().numpy()\n","        for a in x_labels:\n","          all_labels.append(a)\n","\n","      auc1 = roc_auc_score(all_labels,prob)\n","      avg_val_loss = val_loss_epoch / val_step\n","      test_loss.append(avg_val_loss)\n","      test_auc.append(auc1)\n","      \n","      metric = num_correct / metric_count\n","      test_acc.append(metric)\n","      writer.add_scalar(\"test_loss\", avg_val_loss, epoch+1)\n","      writer.add_scalar(\"test_accuracy\", metric, epoch + 1)\n","      writer.add_scalar(\"test_AUC\", auc1, epoch + 1)\n","\n","  torch.save(model.state_dict(), f\"epoch{epoch+1}.pth\")\n","\n","print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n","writer.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t3ctYqxwkRz4","executionInfo":{"status":"aborted","timestamp":1635598772145,"user_tz":-60,"elapsed":5,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["record1 = pd.DataFrame()\n","record1['train_loss'] = train_loss\n","record1['valid_loss'] = valid_loss\n","record1['test_loss'] = test_loss\n","record1['valid_acc'] = valid_acc\n","record1['valid_auc'] = valid_auc\n","record1['test_acc'] = test_acc\n","record1['test_auc'] = test_auc\n","record1.to_csv('experiment_1csv')"],"execution_count":null,"outputs":[]}]}