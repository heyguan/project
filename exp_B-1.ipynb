{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"exp_B-1.ipynb","provenance":[{"file_id":"1zeFQfo4hyrNfIUQagXjt_jqTE2BDz-Y8","timestamp":1634899143442}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1GAMELGRWIxIC8IiTFrYqt-iRh6j0oERs","authorship_tag":"ABX9TyPLH5nd2eWJNAnNRyXuirPI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ocAr6_hCUFSu"},"source":["1. upload BraTS2021_Training_Data.tar to google drive\n","2. unzip BraTS2021_Training_Data.tar to /content/brats\n","3. install monai packages"]},{"cell_type":"code","metadata":{"id":"otZsDSrQJD0H"},"source":["!mkdir brats\n","!7z x -aos /content/drive/MyDrive/BraTS2021_Training_Data.tar -o/content/brats\n","!pip install monai"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NCoohPncILt-"},"source":["import os\n","import cv2\n","import glob\n","import PIL\n","import shutil\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from skimage import data\n","from skimage.util import montage \n","import skimage.transform as skTrans\n","from skimage.transform import rotate\n","from skimage.transform import resize\n","from PIL import Image, ImageOps  \n","\n","import scipy\n","import nibabel as nib\n","from monai.transforms import Compose, Resize,AddChannel\n","import monai\n","\n","import keras\n","import keras.backend as K\n","from keras.callbacks import CSVLogger\n","import tensorflow as tf\n","from tensorflow.keras.utils import plot_model\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n","from tensorflow.keras.layers.experimental import preprocessing\n","from keras.layers import *\n","from keras.models import *\n","\n","np.set_printoptions(precision=3, suppress=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PrxB65YJ2Mr"},"source":["# DEFINE seg-areas  \n","SEGMENT_CLASSES = {\n","    0 : 'NOT tumor',\n","    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE\n","    2 : 'EDEMA',\n","    3 : 'ENHANCING' # original 4 -> converted into 3 later\n","}\n","\n","# there are 155 slices per volume\n","# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \n","VOLUME_SLICES = 100 \n","VOLUME_START_AT = 22 # first slice of volume that we will include\n","IMG_SIZE1=128\n","IMG_SIZE2=128\n","IMG_SIZE3=80\n","\n","TRAIN_DATASET_PATH = '/content/brats'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEvgCy_QhAXt"},"source":["def build_unet(inputs):\n","    conv11 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n","    conc11 = concatenate([inputs, conv11], axis=4)\n","    conv12 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conc11)\n","    conc12 = concatenate([inputs, conv12], axis=4)\n","    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conc12)\n","\n","    conv21 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(pool1)\n","    conc21 = concatenate([pool1, conv21], axis=4)\n","    conv22 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conc21)\n","    conc22 = concatenate([pool1, conv22], axis=4)\n","    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conc22)\n","\n","    conv31 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(pool2)\n","    conc31 = concatenate([pool2, conv31], axis=4)\n","    conv32 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conc31)\n","    conc32 = concatenate([pool2, conv32], axis=4)\n","    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conc32)\n","\n","    conv41 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(pool3)\n","    conc41 = concatenate([pool3, conv41], axis=4)\n","    conv42 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(conc41)\n","    conc42 = concatenate([pool3, conv42], axis=4)\n","    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(conc42)\n","\n","    conv51 = Conv3D(512, (3, 3, 3), activation='relu', padding='same',name='mid_feature_1')(pool4)\n","    conc51 = concatenate([pool4, conv51], axis=4,name='mid_feature')\n","\n","    conv52 = Conv3D(512, (3, 3, 3), activation='relu', padding='same')(conc51)\n","    conc52 = concatenate([pool4, conv52], axis=4,name='mid_feature_2')\n","\n","    up6 = concatenate([Conv3DTranspose(256, (2, 2, 2), strides=(2, 2, 2), padding='same')(conc52), conc42], axis=4)\n","    conv61 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(up6)\n","    conc61 = concatenate([up6, conv61], axis=4)\n","    conv62 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(conc61)\n","    conc62 = concatenate([up6, conv62], axis=4)\n","\n","    up7 = concatenate([Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(conc62), conv32], axis=4)\n","    conv71 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(up7)\n","    conc71 = concatenate([up7, conv71], axis=4)\n","    conv72 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conc71)\n","    conc72 = concatenate([up7, conv72], axis=4)\n","\n","    up8 = concatenate([Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(conc72), conv22], axis=4)\n","    conv81 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(up8)\n","    conc81 = concatenate([up8, conv81], axis=4)\n","    conv82 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conc81)\n","    conc82 = concatenate([up8, conv82], axis=4)\n","\n","    up9 = concatenate([Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(conc82), conv12], axis=4)\n","    conv91 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(up9)\n","    conc91 = concatenate([up9, conv91], axis=4)\n","    conv92 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conc91)\n","    conc92 = concatenate([up9, conv92], axis=4)\n","\n","    conv10 = Conv3D(4, (1, 1, 1), activation='softmax',name='conv10')(conc92)\n","\n","    return Model(inputs=inputs, outputs=conv10)\n","\n","input_layer = Input((IMG_SIZE1, IMG_SIZE2,IMG_SIZE3, 1))\n","\n","model = build_unet(input_layer)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4)] )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PmXJC1RFLDfQ"},"source":["# lists of directories with studies\n","train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n","\n","def pathListIntoIds(dirList):\n","    x = []\n","    for i in range(0,len(dirList)):\n","        x.append(dirList[i][dirList[i].rfind('/')+1:])\n","    return x\n","\n","train_and_test_ids = pathListIntoIds(train_and_val_directories); \n","\n","train_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2,random_state=42) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DV4SjSPrOOgf"},"source":["class DataGenerator(tf.keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_IDs, dim=(IMG_SIZE1,IMG_SIZE2,IMG_SIZE3), batch_size = 1, n_channels = 1, shuffle=True, is_train = True, label = None):\n","        'Initialization'\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.list_IDs = list_IDs\n","        self.n_channels = n_channels\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","        self.transforms = Compose([AddChannel(),Resize((IMG_SIZE1,IMG_SIZE2,IMG_SIZE3))])\n","        self.is_train = is_train\n","        self.label = label\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Find list of IDs\n","        Batch_ids = [self.list_IDs[k] for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(Batch_ids)\n","\n","        if self.is_train == True:\n","          return X, y\n","        else:\n","          return X,y,Batch_ids\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, Batch_ids):\n","        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        X = np.zeros((self.batch_size, *self.dim, self.n_channels))\n","        y = np.zeros((self.batch_size, *self.dim))\n","        Y = np.zeros((self.batch_size, *self.dim, 4))# 4个label 4个通道\n","\n","        # Generate data\n","        for c, i in enumerate(Batch_ids):\n","            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n","\n","            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');\n","            flair = nib.load(data_path).get_fdata()\n","            flair = self.transforms(flair) \n","            \n","            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');\n","            seg = nib.load(data_path).get_fdata()\n","            seg = self.transforms(seg)\n","\n","            flair = flair.squeeze(0)\n","            seg = seg.squeeze(0)\n","\n","\n","            X[c,:,:,:,0] = flair\n","            y[c] = seg\n","\n","        y[y==4] = 3\n","        mask = tf.one_hot(y, 4)\n","        # print(mask.shape)\n","        # Y = tf.image.resize(mask, (IMG_SIZE1, IMG_SIZE2,IMG_SIZE3))\n","        return X/np.max(X), mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxM5MAYjOqj-"},"source":["training_generator = DataGenerator(train_ids)\n","valid_generator = DataGenerator(val_ids,shuffle=False)\n","# test_generator is used for extract middle feature of all MRI images\n","test_generator = DataGenerator(train_and_test_ids,shuffle=False,is_train=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2OpfQmLdQyaN","executionInfo":{"status":"ok","timestamp":1633694935749,"user_tz":-60,"elapsed":184,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}},"outputId":"7aded4b5-0ec3-4f48-8688-66daa59f9e25"},"source":["len(training_generator),len(train_ids),len(train_and_val_directories),len(test_generator)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 1000, 1251, 1251)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"g1OrJspFtEuI"},"source":["csv_logger = CSVLogger('training.log', separator=',', append=False)\n","\n","\n","callbacks = [\n","      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=2, min_lr=0.000001, verbose=1),\n","      CSVLogger('training.log', separator=',', append=False),\n"," keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.h5',verbose=1, save_best_only=True, save_weights_only = True)\n","\n","    ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyENbfCRtIIf"},"source":["K.clear_session()\n","\n","history =  model.fit(training_generator,\n","            epochs=50,\n","            steps_per_epoch=len(train_ids),\n","            callbacks= callbacks,\n","            validation_data = valid_generator,\n","            workers=4\n","                    )  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fhgzcgd0o8Hz"},"source":["# this model will output middle features\n","denseunet_model = Model(inputs=model.input,outputs=model.get_layer('mid_feature').output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V5tWwiP_t5Xy"},"source":["feature = np.zeros((1251,8,8,5,996))\n","id1 = []\n","for idx,data in enumerate(test_generator):\n","  i,j,k = data\n","  xx = k[0].split('_')[-1]\n","  id1.append(xx)\n","  feature_tmp = denseunet_model.predict(i).squeeze(0)\n","  feature[idx]=feature_tmp\n","  # break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dluSVQq_cpM"},"source":["np.save(\"feature.npy\",feature)\n","np.save('id.npy',id1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iphRPjg1X-df"},"source":["I extract the middle feature of all MRI images and their corresponding IDs.\n","\n","Then I pass feature.npy and id.npy to Hao Chen. He will use these features to classify."]}]}