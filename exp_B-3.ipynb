{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"exp_B-3.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1T1JRKdyhcU_nxW0bi4XQZPJZSn_VOqeY","authorship_tag":"ABX9TyPg9lQxOA87kuBFkJrW34Au"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Iz_klSoaseMI"},"source":["1. upload BraTS2021_Training_Data.tar to google drive\n","2. unzip BraTS2021_Training_Data.tar to /content/brats\n","3. install monai packages\n","4. upload the pre-trained model to /content\n","5. upload train_labels.csv to /content"]},{"cell_type":"code","metadata":{"id":"otZsDSrQJD0H"},"source":["!mkdir brats\n","!7z x -aos /content/drive/MyDrive/RSNA_seg/BraTS2021_Training_Data.tar -o/content/brats\n","!cp /content/drive/MyDrive/RSNA_seg/exp_b_1_pretrained.h5 /content\n","!cp /content/drive/MyDrive/train_labels.csv /content\n","!pip install monai"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NCoohPncILt-","executionInfo":{"status":"ok","timestamp":1635604285463,"user_tz":-60,"elapsed":20069,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["import os\n","import cv2\n","import glob\n","import PIL\n","import shutil\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from skimage import data\n","from skimage.util import montage \n","import skimage.transform as skTrans\n","from skimage.transform import rotate\n","from skimage.transform import resize\n","from PIL import Image, ImageOps  \n","\n","import scipy\n","import nibabel as nib\n","\n","from monai.transforms import Compose, Resize,AddChannel,RandGaussianNoise,RandAdjustContrast,ScaleIntensity\n","import monai\n","from sklearn.metrics import roc_auc_score\n","\n","import keras\n","import keras.backend as K\n","from keras.callbacks import CSVLogger\n","import tensorflow as tf\n","from tensorflow.keras.utils import plot_model\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n","from tensorflow.keras.layers.experimental import preprocessing\n","from keras.layers import *\n","from keras.models import *\n","np.set_printoptions(precision=3, suppress=True)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PrxB65YJ2Mr","executionInfo":{"status":"ok","timestamp":1635604286266,"user_tz":-60,"elapsed":3,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["# DEFINE seg-areas  \n","SEGMENT_CLASSES = {\n","    0 : 'NOT tumor',\n","    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE\n","    2 : 'EDEMA',\n","    3 : 'ENHANCING' # original 4 -> converted into 3 later\n","}\n","\n","# there are 155 slices per volume\n","# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \n","VOLUME_SLICES = 100 \n","VOLUME_START_AT = 22 # first slice of volume that we will include\n","IMG_SIZE1=128\n","IMG_SIZE2=128\n","IMG_SIZE3=80\n","\n","TRAIN_DATASET_PATH = '/content/brats'\n","pre_trained_model_path = \"/content/exp_b_1_pretrained.h5\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykgKCtVYv2Ux","executionInfo":{"status":"ok","timestamp":1635605370311,"user_tz":-60,"elapsed":539,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["def build_unet(inputs):\n","    conv11 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n","    conc11 = concatenate([inputs, conv11], axis=4)\n","    conv12 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conc11)\n","    conc12 = concatenate([inputs, conv12], axis=4)\n","    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conc12)\n","\n","    conv21 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(pool1)\n","    conc21 = concatenate([pool1, conv21], axis=4)\n","    conv22 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conc21)\n","    conc22 = concatenate([pool1, conv22], axis=4)\n","    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conc22)\n","\n","    conv31 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(pool2)\n","    conc31 = concatenate([pool2, conv31], axis=4)\n","    conv32 = Conv3D(128, (3, 3, 3), activation='relu', padding='same',name='123')(conc31)\n","    conc32 = concatenate([pool2, conv32], axis=4)\n","    pool3 = MaxPooling3D(pool_size=(2, 2, 2),name='pool3')(conc32)\n","\n","    conv41 = Conv3D(256, (3, 3, 3), activation='relu', padding='same',name='conv41')(pool3)\n","    conc41 = concatenate([pool3, conv41], axis=4)\n","    conv42 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(conc41)\n","    conc42 = concatenate([pool3, conv42], axis=4)\n","    pool4 = MaxPooling3D(pool_size=(2, 2, 2))(conc42)\n","\n","    conv51 = Conv3D(512, (3, 3, 3), activation='relu', padding='same',name='mid_feature_1')(pool4)\n","    conc51 = concatenate([pool4, conv51], axis=4,name='mid_feature')\n","\n","\n","\n","    conv52 = Conv3D(512, (3, 3, 3), activation='relu', padding='same')(conc51)\n","    conc52 = concatenate([pool4, conv52], axis=4,name='mid_feature_2')\n","\n","    up6 = concatenate([Conv3DTranspose(256, (2, 2, 2), strides=(2, 2, 2), padding='same')(conc52), conc42], axis=4)\n","    conv61 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(up6)\n","    conc61 = concatenate([up6, conv61], axis=4)\n","    conv62 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(conc61)\n","    conc62 = concatenate([up6, conv62], axis=4)\n","\n","    up7 = concatenate([Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(conc62), conv32], axis=4)\n","    conv71 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(up7)\n","    conc71 = concatenate([up7, conv71], axis=4)\n","    conv72 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conc71)\n","    conc72 = concatenate([up7, conv72], axis=4)\n","\n","    up8 = concatenate([Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(conc72), conv22], axis=4)\n","    conv81 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(up8)\n","    conc81 = concatenate([up8, conv81], axis=4)\n","    conv82 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conc81)\n","    conc82 = concatenate([up8, conv82], axis=4)\n","\n","    up9 = concatenate([Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(conc82), conv12], axis=4)\n","    conv91 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(up9)\n","    conc91 = concatenate([up9, conv91], axis=4)\n","    conv92 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conc91)\n","    conc92 = concatenate([up9, conv92], axis=4,name='conc92')\n","\n","    conv10 = Conv3D(4, (1, 1, 1), activation='softmax',name='seg_m')(conc92)\n","\n","    return Model(inputs=inputs, outputs=conv10)\n","\n","input_layer = Input((IMG_SIZE1, IMG_SIZE2,IMG_SIZE3, 1))\n","\n","model = build_unet(input_layer)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"BYb_pl20lv9J","executionInfo":{"status":"ok","timestamp":1635605374926,"user_tz":-60,"elapsed":2010,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["model.load_weights(pre_trained_model_path)  "],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"kfeuvUbqlunj","executionInfo":{"status":"ok","timestamp":1635604299507,"user_tz":-60,"elapsed":11,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["# get the layer before the last layer of decoder\n","lastlayer_model = Model(inputs=model.input,outputs=model.get_layer('conc92').output)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"bAkzssyMmwEE","executionInfo":{"status":"ok","timestamp":1635605381343,"user_tz":-60,"elapsed":267,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["# set all parameters of lastlayer_model untrainable\n","def mask_model(g,inputs):\n","    concat = g(inputs)\n","    g.trainable = False\n","    output1 = Conv3D(4, (1, 1, 1), activation='softmax',name='seg_m')(concat)\n","    output2 = Conv3D(4, (1, 1, 1), activation='softmax',name='seg_n')(concat)\n","    return Model(inputs=inputs,outputs=[output1,output2])\n","input_layer = Input((128,128,80,1))\n","new_model = mask_model(lastlayer_model,input_layer)\n","new_model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4)])\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"PmXJC1RFLDfQ","executionInfo":{"status":"ok","timestamp":1635604299727,"user_tz":-60,"elapsed":2,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["cls_df = pd.read_csv('train_labels.csv')\n","cls_id = cls_df['BraTS21ID'].values\n","cls_label = cls_df['MGMT_value'].values\n","\n","d1=zip(cls_id,cls_label)\n","label_dict = dict(d1)\n","\n","# lists of directories with studies\n","train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n","\n","def pathListIntoIds(dirList):\n","    x = []\n","    for i in range(0,len(dirList)):\n","        x.append(dirList[i][dirList[i].rfind('/')+1:])\n","    return x\n","\n","train_and_test_ids = pathListIntoIds(train_and_val_directories); \n","\n","only_id = []\n","new_train_and_test_ids = [] # means that these ids have corresponding MRI images, masks, labels of methylation\n","for i in range(len(train_and_test_ids)):\n","  only = int(train_and_test_ids[i].split('_')[-1])\n","  if only in cls_id:\n","    only_id.append(only)\n","    new_train_and_test_ids.append(train_and_test_ids[i])\n","\n","train_ids, val_ids = train_test_split(new_train_and_test_ids,test_size=0.2,random_state=42) "],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"HcdInwNZyhE8","executionInfo":{"status":"ok","timestamp":1635604300000,"user_tz":-60,"elapsed":2,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["class DataGenerator(tf.keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_IDs, dim=(IMG_SIZE1,IMG_SIZE2,IMG_SIZE3), batch_size = 1, n_channels = 1, shuffle=True, is_train = True, label = None,test=False):\n","        'Initialization'\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.list_IDs = list_IDs\n","        self.n_channels = n_channels\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","        self.transforms = Compose([AddChannel(),Resize((IMG_SIZE1,IMG_SIZE2,IMG_SIZE3))])\n","        self.is_train = is_train\n","        self.label = label\n","        self.test = test\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Find list of IDs\n","        Batch_ids = [self.list_IDs[k] for k in indexes]\n","\n","\n","        # Generate data\n","        X, [y1,y2] = self.__data_generation(Batch_ids)\n","\n","        label_y = np.zeros(len(Batch_ids))\n","        for x in range(len(Batch_ids)):\n","          x1 = int(Batch_ids[x].split('_')[-1])\n","          label_y[x]=(self.label[x1])\n","        \n","        \n","\n","        if self.test == True:\n","          return X,label_y\n","        elif self.is_train == True:\n","          # return X, [label_z]\n","          return X, [y1,y2]\n","        else:\n","          return X,Batch_ids\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, Batch_ids):\n","        'Generates data containing batch_size samples' \n","\n","        X = np.zeros((self.batch_size, *self.dim, self.n_channels))\n","        y = np.zeros((self.batch_size, *self.dim))\n","\n","\n","        label_z = np.zeros(len(Batch_ids))\n","        for x in range(len(Batch_ids)):\n","          x1 = int(Batch_ids[x].split('_')[-1])\n","          label_z[x]=(self.label[x1])\n","\n","        \n","        \n","        # Generate data\n","        for c, i in enumerate(Batch_ids):\n","            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n","\n","            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');\n","            flair = nib.load(data_path).get_fdata()\n","            flair = self.transforms(flair)\n","            \n","            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');\n","            seg = nib.load(data_path).get_fdata()\n","            seg = self.transforms(seg)\n","\n","            flair = flair.squeeze(0)\n","            seg = seg.squeeze(0)\n","\n","            X[c,:,:,:,0] = flair\n","            y[c] = seg\n","\n","        y[y==4] = 3\n","        mask = tf.one_hot(y, 4)\n","\n","        white = np.ones((self.batch_size,*self.dim,1))\n","        zeros12 = np.zeros((self.batch_size,*self.dim,1))\n","\n","        background = np.concatenate((white,zeros12,zeros12,zeros12),axis=-1)\n","\n","        mask_3labels = mask\n","\n","        seg_m = np.zeros((self.batch_size, *self.dim, 4)) #set their corresponding seg_m and seg_n\n","        seg_n = np.zeros((self.batch_size, *self.dim, 4))\n","        \n","        for xx in range(len(label_z)):\n","          if label_z[xx] == 1:\n","            seg_m[xx] = background[xx]\n","            seg_n[xx] = mask_3labels[xx]\n","          else:\n","            seg_m[xx] = mask_3labels[xx]\n","            seg_n[xx] = background[xx] \n","\n","        return X/np.max(X), [seg_m, seg_n]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ipcTuFUZqESr","executionInfo":{"status":"ok","timestamp":1635605345542,"user_tz":-60,"elapsed":755,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["training_generator = DataGenerator(train_ids,label=label_dict)\n","valid_generator = DataGenerator(val_ids,shuffle=False,label=label_dict)\n","test_generator = DataGenerator(new_train_and_test_ids,shuffle=False, label=label_dict,is_train=False, test=False)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"g1OrJspFtEuI","executionInfo":{"status":"ok","timestamp":1635604300001,"user_tz":-60,"elapsed":3,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["callbacks = [\n","      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=2, min_lr=0.000001, verbose=1),\n","      CSVLogger('training.log', separator=',', append=False),\n"," keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.h5',verbose=1, save_best_only=True, save_weights_only = True)\n","        # csv_logger\n","    ]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"hyENbfCRtIIf"},"source":["K.clear_session()\n","\n","history =  new_model.fit(training_generator,\n","            epochs=35,\n","            steps_per_epoch=len(train_ids),\n","            callbacks= callbacks,\n","            validation_data = valid_generator\n","                    )  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rz6aOVjqp9yF"},"source":["After training above model, I got 2 way to classify\n","1. generate their seg-m and seg-n , then save them. Then use these to train classification model\n","2. connect segmentation model and classification model, which set segmentation model untrainable and classification model trainable. then forward MRI images."]},{"cell_type":"markdown","metadata":{"id":"ZpZjfPuiqmnA"},"source":["The first way:"]},{"cell_type":"code","metadata":{"id":"jlb3IyrJqtqj"},"source":["o_masks1 = np.zeros((574,128,128,80,4),dtype=np.float16)\n","o_masks2 = np.zeros((574,128,128,80,4),dtype=np.float16)\n","id1 = np.zeros((574),dtype=np.float16)\n","\n","for idx, data in enumerate(test_generator):\n","  images,idd=data\n","  output_masks1,output_masks2 = new_model.predict(images)#shape should be 2,128,128,80,4\n","  o_masks1[idx]=output_masks1\n","  o_masks2[idx]=output_masks2\n","  idd = int(idd[0].split('_')[-1])\n","  id1[idx] = idd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4eMDSlWts6aC"},"source":["np.save(\"mask1.npy\",o_masks1)\n","np.save(\"mask2.npy\",o_masks1)\n","np.save('id_mask.npy',id1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VQP-V2GCqqvB"},"source":["The second way:"]},{"cell_type":"code","metadata":{"id":"_fscsRcX3wLa"},"source":["def final_model(g,inputs):\n","    g.trainable = False\n","    mask1, mask2 = g(inputs)\n","    x1 = concatenate([mask1, mask2], axis=4)\n","    x2 = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(x1)\n","    x3 = MaxPooling3D(pool_size=(2, 2, 2))(x2)\n","    x4 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(x3)\n","    x5 = MaxPooling3D(pool_size=(2, 2, 2))(x4)\n","    x6 = Flatten()(x5)\n","    x7 = Dense(1024,activation='relu')(x6)\n","    x8 = Dense(1,activation='sigmoid')(x7)\n","    return Model(inputs=inputs, outputs=x8)\n","input_layer = Input((128,128,80,1))\n","new_model = final_model(new_model,input_layer)\n","new_model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),metrics = ['accuracy',tf.keras.metrics.AUC()])\n","\n","new_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lkk0ovYmDzSA","executionInfo":{"status":"ok","timestamp":1635605408910,"user_tz":-60,"elapsed":297,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["callbacks = [\n","#     keras.callbacks.EarlyStopping(monitor='loss', min_delta=0,\n","#                               patience=2, verbose=1, mode='auto'),\n","      keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=2, min_lr=0.000001, verbose=1),\n","      CSVLogger('training2.log', separator=',', append=False),\n"," keras.callbacks.ModelCheckpoint(filepath = 'model_.{epoch:02d}-{val_loss:.6f}.h5',verbose=1, save_best_only=True, save_weights_only = True)\n","        # csv_logger\n","    ]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aw1g4yc2J8N","executionInfo":{"status":"ok","timestamp":1635605410190,"user_tz":-60,"elapsed":299,"user":{"displayName":"max bay","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14342188811040772920"}}},"source":["training2_generator = DataGenerator(train_ids,label=label_dict,test=True)\n","valid2_generator = DataGenerator(val_ids,shuffle=False,label=label_dict,test=True)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"0VdDAtI0Dwwj"},"source":["history =  new_model.fit(training2_generator,\n","            epochs=35,\n","            steps_per_epoch=len(train_ids),\n","            callbacks= callbacks,\n","            validation_data = valid2_generator\n","                    )  "],"execution_count":null,"outputs":[]}]}